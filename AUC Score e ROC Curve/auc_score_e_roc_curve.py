# -*- coding: utf-8 -*-
"""AUC Score e ROC Curve

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cNCSP9h7XZNMg5nYbnTY-hQBjfdy8OIO

#1 Recrutamento preditivo
A empresa de tecnologia HighTech busca contratar os melhores profissionais do mercado para fazer parte do time e gerar valor para a empresa. A HighTech vem investindo muito nos últimos anos no uso de ciência de dados no setor do RH para trazer ganhos no processo de seleção e recrutamento. O time de ciência de dados junto com o time de RH vem realizando juntos um projeto de recrutamento preditivo.

O recrutamento preditivo é uma técnica de People Analytics para encontrar os melhores candidatos para contratação da empresa, na prática, o recrutamento preditivo aumenta as chances do recrutador potencializar o processo de seleção. Por meio da coleta e análise de dados, é possível avaliar o perfil e o fit cultural dos profissionais para entender se existe uma boa aderência à vaga.

#Problema de negócio:

O objetivo da HighTech é identificar quais são os melhores indicadores para realizar o recrutamento de profissionais.

#Base de dados

Este conjunto de dados consiste em algumas características como: percentual de ensino médio e superior e especialização, experiência de trabalho e ofertas salariais para os profissionais colocados.

#Desafio

Você como cientista de dados do time de dados da HighTech tem o desafio de criar um modelo preditivo de recrutamento para prever como e quais são as melhores variáveis que podem colocar um profissional bem qualificado na HighTech.
"""

import pandas as pd

dados = pd.read_excel("/content/Recrutamento.xlsx")
dados.head(3)

dados.shape

set(dados.status)

dados.describe()

dados.info()

import missingno as msno

msno.matrix(dados)

dados.isnull().sum()

import seaborn as sb

sb.boxplot(x="status", y="salary", data=dados, palette="hls")

dados["salary"].fillna(value=0, inplace=True)
dados.head()

dados.isnull().sum()

sb.boxplot(x=dados["hsc_p"])

sb.histplot(data=dados, x="hsc_p")

sb.boxplot(x=dados["degree_p"])

sb.histplot(data=dados, x="degree_p")

sb.boxplot(x=dados["etest_p"])

sb.histplot(data=dados, x="etest_p")

sb.boxplot(x=dados["mba_p"])

sb.histplot(data=dados, x="mba_p")

sb.boxplot(x=dados["salary"])

sb.histplot(data=dados, x="salary")

sb.set_theme(style="whitegrid", palette="muted")
ax=sb.swarmplot(data=dados, x="mba_p", y="status", hue="workex")
ax.set(ylabel="Pontuação para MBA")

! pip install plotly_express

import plotly_express as px

px.violin(dados, y="salary", x="specialisation", color="gender", box=True, points="all")

import matplotlib.pyplot as plt

sb.pairplot(dados,vars=['ssc_p','hsc_p','degree_p','mba_p','etest_p'],hue="status")

correlation_matriz = dados.corr().round(2)

fig, ax = plt.subplots(figsize=(8,8))
sb.heatmap(data = correlation_matriz, annot=True, linewidths=5, ax=ax)
# sem informações das colunas com textos, preciso dar valores para os textos

"""Aqui somente conseguimos analisar a correlação entre as variáveis numéricas. Será que não seria importante também entender a correlação com as variéveis numéricas?

Vamos aplicar técnicas de transformação nos dados:

Vamos utilizar label enconder para tratar variáveis categoricas que possuem apenas dois tipos de categorias, como genero, especialização e status.

Para as demais categorias, vamos aplicar a tecnica de one hot enconing.
"""

from sklearn.preprocessing import LabelEncoder

dados.head()

# para textos que podem sere repreentados de forma binaria (0 e 1) (LabelEncoder)
colunas=["gender", "workex", "specialisation", "status"]
label_encoder = LabelEncoder()
for col in colunas:
  dados[col] = label_encoder.fit_transform(dados[col])

dados.head()

# tratativa de dados para mais valores com mais opções de textos. (OnehotEncoder)
dummy_hsc_s = pd.get_dummies(dados["hsc_s"], prefix="dummy")
dummy_degree_t = pd.get_dummies(dados["degree_t"], prefix="dummy")

dados_dummy=pd.concat([dados, dummy_hsc_s, dummy_degree_t], axis=1)

dados_dummy.head(3)

dados_dummy.drop(["hsc_s", "degree_t", "salary"],axis=1, inplace=True)
dados_dummy.head(2)

correlation_matriz = dados_dummy.corr().round(2)

fig, ax = plt.subplots(figsize=(12,12))
sb.heatmap(data = correlation_matriz, annot=True, linewidths=5, ax=ax)
# COM informações das colunas com textos alteradas para numericas

"""Agora, conseguimos analisar as correlações!

Analisando a correlação e a análise de dados, podemos considerar algumas variáveis como possíveis fortes features para nosso modelo de classificação!

Mas lembre-se, correlação não é causalidade!

Analisando algumas variáveis e sua correlação com a variável status, podemos identificar que as variáveis workex, degree_p, hsc_p e ssc_p possuem uma correlação interessante na contratação.

A maior correlação de status de contratação está com o score de ssc_p, ou seja, pessoas com alto score de ssc_p são mais contratadas.

Vamos analisar?
"""

sb.relplot(x="status", y="ssc_p", hue="status", size="ssc_p",
            sizes=(40, 400), alpha=.5, palette="muted",
            height=6, data=dados_dummy)

x=dados_dummy[["ssc_p", "hsc_p", "degree_p", "workex", "mba_p"]]
y=dados_dummy["status"]

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, stratify=y, random_state=7)

x_train.shape

y_train.shape

from sklearn.preprocessing import StandardScaler, MinMaxScaler

scaler = StandardScaler()
scaler.fit(x_train)
x_train_scalonado=scaler.transform(x_train)
x_test_scalonado = scaler.transform(x_test)

x

x_train_scalonado

import numpy as np

"""#1.1 KNN"""

#função para descobrir o melhor K para a melhor precisão para o modelo
error = []
for i in range(1,10):
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(x_train_scalonado, y_train)
  pred_i = knn.predict(x_test_scalonado)
  error.append(np.mean(pred_i!= y_test))

plt.figure(figsize=(12,6))
plt.plot(range(1,10), error, color="red", linestyle="dashed", marker="o", markerfacecolor="blue", markersize=10)
plt.title("Erro Médio para K")
plt.xlabel("Valor de 'K' ")
plt.ylabel("Erro Médio")

#modfelo com o K escolhido em n_neighborns = 5
modelo_classificador=KNeighborsClassifier(n_neighbors=5)
modelo_classificador.fit(x_train_scalonado, y_train)
y_predito=modelo_classificador.predict(x_test_scalonado)

y_predito

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # matriz de confusão
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

matriz_confusao = confusion_matrix(y_true = y_test,    #dados reais
                                   y_pred = y_predito #dados predito
                                   )

# plotando uma figura com a matriz de confusao
figure = plt.figure(figsize=(15, 5))

disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao)

disp.plot(values_format='d')

# Metricas de precisão, revocação, f1-score e acurácia.
print(classification_report(y_test, y_predito)) #relatório de validação das métrica de desempenho.

from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC

svm = Pipeline([
    ("linear_svc", LinearSVC(C=1))
])

svm.fit(x_train_scalonado, y_train)

y_predito_svm = svm.predict(x_test_scalonado)

matriz_confusao_svm = confusion_matrix(y_true = y_test,       #dados reais
                                   y_pred = y_predito_svm #dados predito
                                   )

# plotando uma figura com a matriz de confusao
figure = plt.figure(figsize=(15, 5))

disp = ConfusionMatrixDisplay(confusion_matrix = matriz_confusao_svm)

disp.plot(values_format='d')

# Metricas de precisão, revocação, f1-score e acurácia.
print(classification_report(y_test, y_predito_svm)) #relatório de validação das métrica de desempenho.

from sklearn import metrics
from sklearn.metrics import roc_curve, auc

y_prob = modelo_classificador.predict_proba(x_test_scalonado)[:,1]

false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(false_positive_rate, true_positive_rate)
roc_auc

import matplotlib.pyplot as plt

plt.figure(figsize=(10,10))
plt.title('Receiver Operating Characteristic')
plt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],linestyle='--')
plt.axis('tight')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

